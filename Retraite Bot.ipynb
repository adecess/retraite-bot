{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ba28ad9-8852-4615-90e9-832f01dca94a",
   "metadata": {},
   "source": [
    "1. A user mentions bot @parrepartition\n",
    "2. The script finds that new @parrepartition mention and then reads the parent tweet it is being mentioned on\n",
    "3. The script takes that parent tweet and generates a response relevant with the French pension system using a language model\n",
    "4. Respond is posted and tweet is logged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a6685e-5471-4980-a426-f3d217e95507",
   "metadata": {},
   "source": [
    "This notebook focuses on #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85b437f8-ccdb-4957-86b6-3d467607e75f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Using cached langchain-0.2.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./retraite-venv/lib/python3.12/site-packages (from langchain) (6.0.1)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Using cached SQLAlchemy-2.0.30-cp312-cp312-macosx_10_9_x86_64.whl.metadata (9.6 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Using cached aiohttp-3.9.5-cp312-cp312-macosx_10_9_x86_64.whl.metadata (7.5 kB)\n",
      "Collecting langchain-core<0.3.0,>=0.2.0 (from langchain)\n",
      "  Downloading langchain_core-0.2.3-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
      "  Using cached langchain_text_splitters-0.2.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.1.67-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting numpy<2,>=1 (from langchain)\n",
      "  Using cached numpy-1.26.4-cp312-cp312-macosx_10_9_x86_64.whl.metadata (61 kB)\n",
      "Collecting pydantic<3,>=1 (from langchain)\n",
      "  Downloading pydantic-2.7.2-py3-none-any.whl.metadata (108 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.5/108.5 kB\u001b[0m \u001b[31m863.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m965.5 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2 in ./retraite-venv/lib/python3.12/site-packages (from langchain) (2.32.3)\n",
      "Collecting tenacity<9.0.0,>=8.1.0 (from langchain)\n",
      "  Using cached tenacity-8.3.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./retraite-venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached frozenlist-1.4.1-cp312-cp312-macosx_10_9_x86_64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached multidict-6.0.5-cp312-cp312-macosx_10_9_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached yarl-1.9.4-cp312-cp312-macosx_10_9_x86_64.whl.metadata (31 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.0->langchain)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting packaging<24.0,>=23.2 (from langchain-core<0.3.0,>=0.2.0->langchain)\n",
      "  Using cached packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Using cached orjson-3.10.3-cp312-cp312-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata (49 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1->langchain)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.18.3 (from pydantic<3,>=1->langchain)\n",
      "  Downloading pydantic_core-2.18.3-cp312-cp312-macosx_10_12_x86_64.whl.metadata (6.5 kB)\n",
      "Collecting typing-extensions>=4.6.1 (from pydantic<3,>=1->langchain)\n",
      "  Using cached typing_extensions-4.12.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./retraite-venv/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./retraite-venv/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./retraite-venv/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./retraite-venv/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Using cached greenlet-3.0.3-cp312-cp312-macosx_11_0_universal2.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./retraite-venv/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain) (2.4)\n",
      "Using cached langchain-0.2.1-py3-none-any.whl (973 kB)\n",
      "Using cached aiohttp-3.9.5-cp312-cp312-macosx_10_9_x86_64.whl (395 kB)\n",
      "Downloading langchain_core-0.2.3-py3-none-any.whl (310 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.2/310.2 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached langchain_text_splitters-0.2.0-py3-none-any.whl (23 kB)\n",
      "Downloading langsmith-0.1.67-py3-none-any.whl (124 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.4/124.4 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached numpy-1.26.4-cp312-cp312-macosx_10_9_x86_64.whl (20.3 MB)\n",
      "Downloading pydantic-2.7.2-py3-none-any.whl (409 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.5/409.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.18.3-cp312-cp312-macosx_10_12_x86_64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached SQLAlchemy-2.0.30-cp312-cp312-macosx_10_9_x86_64.whl (2.1 MB)\n",
      "Using cached tenacity-8.3.0-py3-none-any.whl (25 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached frozenlist-1.4.1-cp312-cp312-macosx_10_9_x86_64.whl (53 kB)\n",
      "Using cached greenlet-3.0.3-cp312-cp312-macosx_11_0_universal2.whl (273 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached multidict-6.0.5-cp312-cp312-macosx_10_9_x86_64.whl (29 kB)\n",
      "Using cached orjson-3.10.3-cp312-cp312-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (253 kB)\n",
      "Using cached packaging-23.2-py3-none-any.whl (53 kB)\n",
      "Using cached typing_extensions-4.12.0-py3-none-any.whl (37 kB)\n",
      "Using cached yarl-1.9.4-cp312-cp312-macosx_10_9_x86_64.whl (81 kB)\n",
      "Installing collected packages: typing-extensions, tenacity, packaging, orjson, numpy, multidict, jsonpatch, greenlet, frozenlist, annotated-types, yarl, SQLAlchemy, pydantic-core, aiosignal, pydantic, aiohttp, langsmith, langchain-core, langchain-text-splitters, langchain\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 24.0\n",
      "    Uninstalling packaging-24.0:\n",
      "      Successfully uninstalled packaging-24.0\n",
      "Successfully installed SQLAlchemy-2.0.30 aiohttp-3.9.5 aiosignal-1.3.1 annotated-types-0.7.0 frozenlist-1.4.1 greenlet-3.0.3 jsonpatch-1.33 langchain-0.2.1 langchain-core-0.2.3 langchain-text-splitters-0.2.0 langsmith-0.1.67 multidict-6.0.5 numpy-1.26.4 orjson-3.10.3 packaging-23.2 pydantic-2.7.2 pydantic-core-2.18.3 tenacity-8.3.0 typing-extensions-4.12.0 yarl-1.9.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b63cd49-c5b8-4e34-8bea-707f1c538894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -qU langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c140706b-279f-4e1a-af5e-d260d01ed95c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87df4a5c-2a32-4710-87cf-64388188b407",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate, SystemMessagePromptTemplate, AIMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3469c4d7-5bf4-4f56-ac49-5c1137456616",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.7,\n",
    "                 api_key=OPENAI_API_KEY,\n",
    "                 model_name='gpt-3.5-turbo',\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8b9a41-65c2-4901-b0f7-a439ba7683fc",
   "metadata": {},
   "source": [
    "Then let's create our function that will take in a piece of a text (a tweet) and give us an output response\n",
    "\n",
    "    You are a French economist and a professor of finance at Wharton School of the University of Pennsylvania. You are critical but unbiased about the French unfunded pension system. You think that introducing a dose of private and funded pension plans into the French system would make it more sustainable and beneficial to French pensioners. Your goal is to give a concise prediction in response to a piece of text from a French user.\n",
    "\n",
    "    % RESPONSE TONE:\n",
    "\n",
    "        Your prediction should be opinionated, factual and given in a respectable voice\n",
    "        Your tone should be serious but not too much\n",
    "\n",
    "    % RESPONSE FORMAT:\n",
    "\n",
    "        Respond in French\n",
    "        Respond in under 200 characters\n",
    "        Respond in one short sentence\n",
    "        Do not respond with emojis\n",
    "\n",
    "    % RESPONSE CONTENT:\n",
    "\n",
    "        Include specific examples of pension systems if they are relevant\n",
    "        If you don't have an answer, say, \"Je ne sais pas quoi penser de votre avis.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e55fbd-e37c-485d-a227-b54b7193a447",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
